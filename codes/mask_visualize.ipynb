{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTING NECESSARY MODULES\n",
    "import mrcnn\n",
    "import mrcnn.config\n",
    "import mrcnn.model\n",
    "import mrcnn.visualize\n",
    "import mrcnn.utils\n",
    "import cv2 as cv\n",
    "import os\n",
    "import skimage.io\n",
    "import numpy as np\n",
    "import pickle\n",
    "from lib.visualizer import show_images\n",
    "from lib.homography import find_homography\n",
    "import csv\n",
    "\n",
    "import tensorflow as tf\n",
    "print('Tensorflow Version: ',tf.__version__)\n",
    "import h5py\n",
    "print('h5py Version: ',h5py.__version__)\n",
    "\n",
    "\n",
    "# FEW DIRECTORIES\n",
    "MODEL_DIR = './logs/mask_RCNN_logs/'\n",
    "COCO_MODEL_PATH = './data/weights/mask_rcnn_coco.h5'\n",
    "DATA_DIR = './data/aoa_data'\n",
    "RESULTS_DIR = './results/images'\n",
    "PIXEL_DIR = './results/pixels/'\n",
    "\n",
    "\n",
    "# Class Names\n",
    "class_names = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
    "               'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "               'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n",
    "               'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n",
    "               'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
    "               'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "               'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
    "               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
    "               'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "               'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "               'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
    "               'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
    "               'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
    "               'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
    "               'teddy bear', 'hair drier', 'toothbrush']\n",
    "\n",
    "# CALIBRATION MATRIX FOR POINTS CALIBRATION\n",
    "calibration_matrix = np.array([ [ 1,0,0],[0,1,0],[0,0,1]])\n",
    "\n",
    "\n",
    "# RANDOM COLORS\n",
    "colors = [[255,0,0],[0,255,0],[0,0,255],[255,255,0],[75, 200, 214],[202, 241, 109],[223, 117, 230],[138, 135, 243]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MASK RCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceConfig(mrcnn.config.Config):\n",
    "    # Name of the Configuration\n",
    "    NAME = 'coco_inference'\n",
    "\n",
    "    # GPU Parameters\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "    # Number of class = number of classes +1(Background)\n",
    "    NUM_CLASSES = len(class_names)\n",
    "\n",
    "config = InferenceConfig()\n",
    "\n",
    "# Initialize the Mask R-CNN model for inference and then load the weights.\n",
    "model = mrcnn.model.MaskRCNN(mode=\"inference\", config=config, model_dir=MODEL_DIR)\n",
    "\n",
    "# Load the weights into the model.\n",
    "model.load_weights(filepath=COCO_MODEL_PATH, by_name=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***DEMO***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = './data/demo/mask_RCNN.jpg'\n",
    "image = skimage.io.imread(file_name)\n",
    "\n",
    "\n",
    "# Perform a forward pass of the network to obtain the results\n",
    "r = model.detect([image], verbose=1)\n",
    "\n",
    "# Get the results for the first image.\n",
    "r = r[0]\n",
    "\n",
    "# Visualize the detected objects.\n",
    "mrcnn.visualize.display_instances(image=image, \n",
    "                                boxes=r['rois'], \n",
    "                                masks=r['masks'], \n",
    "                                class_ids=r['class_ids'], \n",
    "                                class_names=class_names, \n",
    "                                scores=r['scores'])\n",
    "\n",
    "# VISUALIZING ONLY THE BOTTLES\n",
    "bottle_index = np.array([i for (i, item) in enumerate(r['class_ids']) if class_names[item]=='bottle' ])\n",
    "mrcnn.visualize.display_instances(image, r['rois'][bottle_index], r['masks'][:,:,bottle_index],r['class_ids'][bottle_index] , \n",
    "                            class_names, r['scores'][bottle_index],save_fig_path = './results/demo/mask_RCNN.jpg')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***MASK RCNN Model Detection***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 300*400\n",
    "for i in os.listdir(DATA_DIR):\n",
    "    if i.split('.')[-1] != 'jpg':\n",
    "        continue\n",
    "    print(os.path.join(DATA_DIR,i))\n",
    "    image = cv.imread(os.path.join(DATA_DIR,i))\n",
    "    results = model.detect([image],verbose = 0)\n",
    "    r = results[0]\n",
    "    arr = np.array([i for (i, mask) in enumerate(r['masks'].T) if np.count_nonzero(mask)< threshold])\n",
    "    r['rois'] = r['rois'][arr]\n",
    "    r['masks'] = r['masks'][:,:,arr]\n",
    "    r['class_ids'] = r['class_ids'][arr]\n",
    "    r['scores'] = r['scores'][arr]\n",
    "\n",
    "    with open(MODEL_DIR+i.split('.')[0]+\".pkl\",\"wb\") as fw:\n",
    "        pickle.dump(r,fw)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CALIBRATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHA = 4\n",
    "points = []\n",
    "\n",
    "def mouse_callback(event, x, y, flags, param):\n",
    "    if event == cv.EVENT_LBUTTONDOWN:\n",
    "        points.append([x*ALPHA,y*ALPHA])\n",
    "\n",
    "f = open('./data/evaluation/calibration/paper.csv','w',newline=\"\")   # APPEND - \"a\" or REWRITE - \"w\"\n",
    "writer = csv.writer(f)\n",
    "\n",
    "\n",
    "count = 0\n",
    "with open(\"./data/evaluation/calculation/paper.txt\", \"r\") as file:\n",
    "    for line in file:\n",
    "        ctnt = line.split('_')\n",
    "        CASE = '_'.join(ctnt[:-2])\n",
    "        L1 = int(ctnt[-2])\n",
    "        L2 = int(ctnt[-1])\n",
    "        print(f\"\\n\\nCASE {count}: {CASE}\")\n",
    "        count = count + 1\n",
    "\n",
    "        \n",
    "        image = cv.imread(os.path.join(DATA_DIR, f\"{CASE}_{L1}.jpg\"))\n",
    "        assert image is not None\n",
    "        image_ = cv.resize(image,(int(image.shape[1]/ALPHA),int(image.shape[0]/ALPHA)))\n",
    "\n",
    "\n",
    "        for i in os.listdir(os.path.join(PIXEL_DIR,f\"{CASE}_{L1}\")):    \n",
    "            src_pt = np.loadtxt(os.path.join(PIXEL_DIR,f\"{CASE}_{L1}\",i), delimiter=',',max_rows=1).astype(int)\n",
    "            print(i.split('.')[0])\n",
    "            print(f\"AoA Center: {src_pt}\\n\")\n",
    "            cv.namedWindow('CALIBRATION')\n",
    "            cv.setMouseCallback('CALIBRATION', mouse_callback)\n",
    "            cv.imshow('CALIBRATION', image_)\n",
    "            cv.waitKey(0)\n",
    "            dst_pt = points[-1]\n",
    "            \n",
    "            tux = (src_pt[0],src_pt[1],dst_pt[0],dst_pt[1])\n",
    "            writer.writerow(tux)\n",
    "    f.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VISUALIZING POINTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_points(CASE, level, METHOD = 'POINTS',mask_RCNN = False):\n",
    "    image = cv.imread(os.path.join(DATA_DIR, f\"{CASE}_{level}.jpg\"))\n",
    "    assert image is not None\n",
    "\n",
    "    file_count = 0\n",
    "\n",
    "    for i in os.listdir(os.path.join(PIXEL_DIR,f\"{CASE}_{level}\")):\n",
    "        file_count = file_count + 1\n",
    "        color = colors[file_count-1]\n",
    "        cv.putText(image, i.split('.')[0], (image.shape[1]-1000, file_count*100),cv.FONT_HERSHEY_DUPLEX, 2, color, 2, cv.LINE_AA)\n",
    "        \n",
    "        \n",
    "        center_pt = np.loadtxt(os.path.join(PIXEL_DIR,f\"{CASE}_{level}\",i), delimiter=',',max_rows=1).astype(int)\n",
    "        center_pt = np.hstack((center_pt,[1]))\n",
    "        calibrated_pt = calibration_matrix@center_pt.T\n",
    "        calibrated_pt = (calibrated_pt[:2]/calibrated_pt[2]).astype('int')\n",
    "        if METHOD == 'CENTERS':\n",
    "            cv.circle(image, calibrated_pt, 50, color, 30)\n",
    "            continue\n",
    "\n",
    "\n",
    "        pts = np.loadtxt(os.path.join(PIXEL_DIR,f\"{CASE}_{level}\",i), delimiter=',',usecols=(0,1),skiprows=1).astype(int)\n",
    "        if len(pts) and pts.ndim == 1:\n",
    "            pts = np.array([pts])\n",
    "        elif pts.ndim != 2:\n",
    "            continue\n",
    "        pts = np.hstack((pts, np.ones((pts.shape[0],1))))\n",
    "        c_pts = np.dot(calibration_matrix,pts.T).T\n",
    "        c_pts = (c_pts[:,:2]/c_pts[:,2:]).astype(int)\n",
    "        counter = 0\n",
    "        hull = cv.convexHull(c_pts)\n",
    "        for item in c_pts:\n",
    "            if METHOD == 'POINTS':\n",
    "                cv.drawMarker(image, (item[0],item[1]), color, markerType=cv.MARKER_STAR,markerSize=40, thickness=2, line_type=cv.LINE_AA)\n",
    "            else:\n",
    "                cv.drawContours(image,[hull],0,color,-1)\n",
    "\n",
    "    if mask_RCNN:\n",
    "        with open(os.path.join(MODEL_DIR, f\"{CASE}_{level}.pkl\"), 'rb') as f:\n",
    "            r = pickle.load(f)\n",
    "\n",
    "        bottle_index = np.array([i for (i, item) in enumerate(r['class_ids']) if class_names[item]=='bottle' ])\n",
    "        mrcnn.visualize.display_instances(image, r['rois'][bottle_index], r['masks'][:,:,bottle_index],r['class_ids'][bottle_index] , class_names, r['scores'][bottle_index],save_fig_path = os.path.join(RESULTS_DIR,f\"{CASE}_{level}.jpg\"))\n",
    "    \n",
    "    else:\n",
    "        return [image,'c',f\"{CASE} - {level}\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Paper***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_pts = np.loadtxt('./data/evaluation/calibration/paper.csv', delimiter=',',usecols=[0,1]).astype(int)   \n",
    "dst_pts = np.loadtxt('./data/evaluation/calibration/paper.csv', delimiter=',',usecols=[2,3]).astype(int)                                \n",
    "calibration_matrix,_ = cv.estimateAffinePartial2D(src_pts,dst_pts)\n",
    "calibration_matrix = np.vstack((calibration_matrix,[[0,0,1]]))\n",
    "\n",
    "result = visualize_points('paper',77,\"POINTS\")\n",
    "show_images([result],size = 10)\n",
    "cv.imwrite('./results/demo/paper.jpg',result[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***SINGLE SLAVE***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "\n",
    "\n",
    "\n",
    "src_pts = np.loadtxt('./data/weights/single_slave.csv', delimiter=',',usecols=[0,1]).astype(int)   \n",
    "dst_pts = np.loadtxt('./data/weights/single_slave.csv', delimiter=',',usecols=[2,3]).astype(int)                                \n",
    "calibration_matrix,_ = cv.estimateAffinePartial2D(src_pts,dst_pts)\n",
    "calibration_matrix = np.vstack((calibration_matrix,[[0,0,1]]))\n",
    "\n",
    "with open(\"./data/weights/single_slave.txt\", \"r\") as file:\n",
    "    for line in file:\n",
    "        ctnt = line.split('_')\n",
    "        CASE = '_'.join(ctnt[:-2])\n",
    "        L1 = int(ctnt[-2])\n",
    "        L2 = int(ctnt[-1])\n",
    "        image = visualize_points(CASE,L1,'CENTERS')\n",
    "        images.append(image)\n",
    "print(len(images))\n",
    "\n",
    "# PICK HOW MANY IMAGES YOU WANT TO BE SIDE BY SIDE\n",
    "n = 5\n",
    "for i_count in range(len(images)//n):\n",
    "    show_images(images[i_count*n:i_count*n+n],size= 3)\n",
    "if len(images)%n:\n",
    "    show_images(images[(i_count+1)*n:(i_count+1)*n+ len(images)%n],size = 3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***TWO SLAVE***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_pts = np.loadtxt('./data/weights/two_slave.csv', delimiter=',',usecols=[0,1]).astype(int)   \n",
    "dst_pts = np.loadtxt('./data/weights/two_slave.csv', delimiter=',',usecols=[2,3]).astype(int)                                \n",
    "calibration_matrix,_ = cv.estimateAffinePartial2D(src_pts,dst_pts)\n",
    "calibration_matrix = np.vstack((calibration_matrix,[[0,0,1]]))\n",
    "\n",
    "images = []\n",
    "with open(\"./data/weights/two_slave.txt\", \"r\") as file:\n",
    "    for line in file:\n",
    "        ctnt = line.split('_')\n",
    "        CASE = '_'.join(ctnt[:-2])\n",
    "        L1 = int(ctnt[-2])\n",
    "        L2 = int(ctnt[-1])\n",
    "        image = visualize_points(CASE,L1,'POINTS')\n",
    "        images.append(image)\n",
    "print(len(images))\n",
    "\n",
    "# PICK HOW MANY IMAGES YOU WANT TO BE SIDE BY SIDE\n",
    "n = 5\n",
    "for i_count in range(len(images)//n):\n",
    "    show_images(images[i_count*n:i_count*n+n],size = 3)\n",
    "if len(images)%n:\n",
    "    show_images(images[(i_count+1)*n:(i_count+1)*n+ len(images)%n],size = 3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***THREE SLAVE***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_pts = np.loadtxt('./data/weights/three_slave.csv', delimiter=',',usecols=[0,1]).astype(int)   \n",
    "dst_pts = np.loadtxt('./data/weights/three_slave.csv', delimiter=',',usecols=[2,3]).astype(int)                                \n",
    "calibration_matrix,_ = cv.estimateAffinePartial2D(src_pts,dst_pts)\n",
    "calibration_matrix = np.vstack((calibration_matrix,[[0,0,1]]))\n",
    "\n",
    "images = []\n",
    "with open(\"./data/weights/three_slave.txt\", \"r\") as file:\n",
    "    for line in file:\n",
    "        ctnt = line.split('_')\n",
    "        CASE = '_'.join(ctnt[:-2])\n",
    "        L1 = int(ctnt[-2])\n",
    "        L2 = int(ctnt[-1])\n",
    "        image = visualize_points(CASE,L1,'POINTS')\n",
    "        images.append(image)\n",
    "print(len(images))\n",
    "\n",
    "# PICK HOW MANY IMAGES YOU WANT TO BE SIDE BY SIDE\n",
    "n = 5\n",
    "for i_count in range(len(images)//n):\n",
    "    show_images(images[i_count*n:i_count*n+n],size= 5)\n",
    "if len(images)%n:\n",
    "    show_images(images[(i_count+1)*n:(i_count+1)*n+ len(images)%n],size= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "with open(\"./data/evaluation/calculation/calculation_reference.txt\", \"r\") as file:\n",
    "    for line in file:\n",
    "        ctnt = line.split('_')\n",
    "        CASE = '_'.join(ctnt[:-2])\n",
    "        L1 = int(ctnt[-2])\n",
    "        L2 = int(ctnt[-1])\n",
    "        image = visualize_points(CASE,L1,'POINTS')\n",
    "        images.append(image)\n",
    "print(len(images))\n",
    "\n",
    "# PICK HOW MANY IMAGES YOU WANT TO BE SIDE BY SIDE\n",
    "n = 5\n",
    "for i_count in range(len(images)//n):\n",
    "    show_images(images[i_count*n:i_count*n+n],size= 5)\n",
    "if len(images)%n:\n",
    "    show_images(images[(i_count+1)*n:(i_count+1)*n+ len(images)%n],size= 3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EVALUATION"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Destination Points***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHA = 4\n",
    "points = []\n",
    "\n",
    "def mouse_callback(event, x, y, flags, param):\n",
    "    if event == cv.EVENT_LBUTTONDOWN:\n",
    "        points.append([x*ALPHA,y*ALPHA])\n",
    "\n",
    "f = open('./results/performance/indoor.csv','w',newline=\"\")   # APPEND - \"a\" or REWRITE - \"w\"\n",
    "writer = csv.writer(f)\n",
    "\n",
    "\n",
    "count = 0\n",
    "with open(\"./data/evaluation/indoor_time.txt\", \"r\") as file:\n",
    "    for line in file:\n",
    "        ctnt = line.split('_')\n",
    "        CASE = '_'.join(ctnt[:-2])\n",
    "        L1 = int(ctnt[-2])\n",
    "        L2 = int(ctnt[-1])\n",
    "        print(f\"\\n\\nCASE {count}: {CASE}\")\n",
    "        count = count + 1\n",
    "\n",
    "        \n",
    "        image = cv.imread(os.path.join(DATA_DIR, f\"{CASE}_{L1}.jpg\"))\n",
    "        assert image is not None\n",
    "        image_ = cv.resize(image,(int(image.shape[1]/ALPHA),int(image.shape[0]/ALPHA)))\n",
    "\n",
    "\n",
    "        for i in os.listdir(os.path.join(PIXEL_DIR,f\"{CASE}_{L1}\")):   \n",
    "            cv.namedWindow('CALIBRATION')\n",
    "            cv.setMouseCallback('CALIBRATION', mouse_callback)\n",
    "            cv.imshow('CALIBRATION', image_)\n",
    "            cv.waitKey(0)\n",
    "            dst_pt = points[-1]\n",
    "            \n",
    "            tux = (dst_pt[0],dst_pt[1])\n",
    "            writer.writerow(tux)\n",
    "    f.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Experimental Points***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('./results/performance/indoor_15.csv','w',newline=\"\")\n",
    "writer = csv.writer(f)\n",
    "\n",
    "src_pts = np.loadtxt('./data/evaluation/time_analysis.csv', delimiter=',',usecols=[0,1]).astype(int)   \n",
    "dst_pts = np.loadtxt('./data/evaluation/time_analysis.csv', delimiter=',',usecols=[2,3]).astype(int)                                \n",
    "calibration_matrix,_ = cv.estimateAffinePartial2D(src_pts,dst_pts)\n",
    "calibration_matrix = np.vstack((calibration_matrix,[[0,0,1]]))\n",
    "\n",
    "\n",
    "count = 0\n",
    "with open(\"./data/evaluation/indoor_time.txt\", \"r\") as file:\n",
    "    for line in file:\n",
    "        ctnt = line.split('_')\n",
    "        CASE = '_'.join(ctnt[:-2])\n",
    "        L1 = int(ctnt[-2])\n",
    "        L2 = int(ctnt[-1])\n",
    "        print(f\"\\n\\nCASE: {CASE}\")\n",
    "        show_images([visualize_points(CASE,L1,'POINTS')])\n",
    "        \n",
    "        image = cv.imread(os.path.join(DATA_DIR, f\"{CASE}_{L1}.jpg\"))\n",
    "        assert image is not None\n",
    "\n",
    "        for i in os.listdir(os.path.join(PIXEL_DIR,f\"{CASE}_{L1}\")):      \n",
    "            print(i.split('.')[0])\n",
    "            src_pt = np.loadtxt(os.path.join(PIXEL_DIR,f\"{CASE}_{L1}\",i), delimiter=',',max_rows=1).astype(int)\n",
    "            src_pt = np.hstack((src_pt,[1]))\n",
    "            calibrated_pt = calibration_matrix@src_pt.T\n",
    "            calibrated_pt = (calibrated_pt[:2]/calibrated_pt[2]).astype('int')\n",
    "            print(f\"AOA_CENTER: {calibrated_pt}\")\n",
    "\n",
    "            tux = (calibrated_pt[0],calibrated_pt[1])\n",
    "            writer.writerow(tux)\n",
    "            count = count + 1\n",
    "            print(count)\n",
    "    f.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MATCHING IDEA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***MATCHING IDEA FROM PREVIOUS STUDENT***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIXEL PROXIMITY BASED MATCHING TECHNIQUE\n",
    "def pixel_proximity_matcher(CASE,level):\n",
    "    image = cv.imread(os.path.join(DATA_DIR, f\"{CASE}_{level}.jpg\"))\n",
    "    assert image is not None\n",
    "    file_count = 0\n",
    "\n",
    "    # loading the mask_RCNN output\n",
    "    with open(os.path.join(MODEL_DIR,f\"{CASE}_{level}.pkl\"), 'rb') as f:\n",
    "        r = pickle.load(f)\n",
    "\n",
    "    masks = r['masks']\n",
    "    scores = r['scores']\n",
    "    num_objects = len(scores)\n",
    "\n",
    "    POINTS_PATH = os.path.join(PIXEL_DIR,f\"L{level}\")\n",
    "    for i in os.listdir(POINTS_PATH):\n",
    "        color = colors[file_count]\n",
    "        file_count = file_count + 1\n",
    "        cv.putText(image, i.split('.')[0], (image.shape[1]-1000, file_count*100),cv.FONT_HERSHEY_DUPLEX, 2, color, 2, cv.LINE_AA)\n",
    "\n",
    "        pts = np.loadtxt(os.path.join(POINTS_PATH,i), delimiter=',',usecols=(0,1),skiprows=1).astype(int)\n",
    "        cts = np.loadtxt(os.path.join(POINTS_PATH,i), delimiter=',',usecols=(2),skiprows=1).astype(int)\n",
    "\n",
    "        pts = np.hstack((pts, np.ones((pts.shape[0],1))))\n",
    "        c_pts = np.dot(calibration_matrix,pts.T).T\n",
    "        c_pts = (c_pts[:,:2]/c_pts[:,2:]).astype(int)\n",
    "\n",
    "        if len(pts) and pts.ndim == 1:\n",
    "            pts = np.array([pts])\n",
    "        elif pts.ndim != 2:\n",
    "            continue\n",
    "\n",
    "        final_score = np.zeros(num_objects)\n",
    "        now_masks = []\n",
    "\n",
    "        for i in range(num_objects):\n",
    "            mask = masks[:,:,i]\n",
    "            count = 0\n",
    "            size = np.where(mask)[0].shape[0]\n",
    "            for p,coordinate in enumerate(c_pts):\n",
    "                x,y = coordinate\n",
    "                if(x>=4000) or(x<0) or y>3000 or y<0:\n",
    "                    continue\n",
    "                if mask[y,x]:\n",
    "                    count += cts[p]\n",
    "            else:\n",
    "                final_score[i] = count/size * scores[i]\n",
    "                now_masks.append(mask)\n",
    "    \n",
    "        k = np.argmax(final_score)\n",
    "        mask = masks[:, :, k]\n",
    "        r[\"final_mask\"] = mask\n",
    "        image[mask] = color\n",
    "        # mask = np.dstack((color[0]*mask,color[1]*mask, color[2]*mask)).astype(np.uint8)\n",
    "        # image = cv.addWeighted(image,1,mask,1,0)\n",
    "\n",
    "        # cv.imwrite(os.path.join(RESULTS_DIR,CASE+f'{file_count}.jpg'), img4)\n",
    "        # r[\"masks\"] = now_masks\n",
    "        # r[\"final_score\"] = final_score\n",
    "    show_images([[image]],size = 10)\n",
    "    return \"SUCESS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_proximity_matcher('three_top_indoor_i',63)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Matching Function-Homography***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HOMOGRAPHY BASED MATCHING TECHNIQUE\n",
    "\n",
    "# FINDING L2 NORM BASED SIMILARITY BETWEEN TWO NUMPY ARRAYS\n",
    "def find_l2_norm(arr1,arr2):\n",
    "    return np.sum((arr1-arr2)**2)\n",
    "\n",
    "\n",
    "# BEST MATCH\n",
    "def find_best_match(ARR, ARRs):\n",
    "    min_distance = None\n",
    "    match_index = 0\n",
    "    for i,arr in enumerate(ARRs):\n",
    "        if min_distance is None or min_distance>find_l2_norm(arr,ARR):\n",
    "            min_distance = find_l2_norm(arr,ARR)\n",
    "            match_index = i\n",
    "    return match_index\n",
    "\n",
    "# FINDING THE CONVEX HULL MASK AROUND A SET OF POINTS\n",
    "def find_mask(SLAVE,LEVEL,SHAPE=(3000,4000)):\n",
    "        pts = np.loadtxt(os.path.join(PIXEL_DIR,f\"L{LEVEL}\",SLAVE), delimiter=',',usecols=(0,1)).astype(int)\n",
    "        if len(pts) and pts.ndim == 1:\n",
    "            pts = np.array([pts])\n",
    "        elif pts.ndim != 2:\n",
    "            return None\n",
    "        pts = np.hstack((pts, np.ones((pts.shape[0],1))))\n",
    "        c_pts = np.dot(calibration_matrix,pts.T).T\n",
    "        c_pts = (c_pts[:,:2]/c_pts[:,2:]).astype(int)\n",
    "        hull = cv.convexHull(c_pts)\n",
    "        hull_mask = np.zeros(SHAPE).astype('uint8')\n",
    "        cv.fillPoly(hull_mask, [hull], 255)\n",
    "        return hull_mask\n",
    "\n",
    "\n",
    "def homography_estimation_mask(CASE,LEVEL1,LEVEL2,matching_order=None):\n",
    "    c_image1 = cv.imread(os.path.join(DATA_DIR, CASE+\"_\"+str(LEVEL1)+'.jpg'))\n",
    "    c_image2 = cv.imread(os.path.join(DATA_DIR, CASE+\"_\"+str(LEVEL2)+'.jpg'))\n",
    "    assert c_image1 is not None\n",
    "    assert c_image2 is not None\n",
    "    image1, image2 = cv.cvtColor(c_image1, cv.COLOR_BGR2GRAY), cv.cvtColor(c_image2,cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    # loading the mask_RCNN output\n",
    "    with open(os.path.join(MODEL_DIR,CASE+\"_\"+str(LEVEL1)+'.pkl'), 'rb') as f:\n",
    "        r1 = pickle.load(f)\n",
    "    with open(os.path.join(MODEL_DIR,CASE+\"_\"+str(LEVEL2)+'.pkl'), 'rb') as f:\n",
    "        r2 = pickle.load(f)\n",
    "    \n",
    "    h_arr = []\n",
    "    for i in range(len(r1['class_ids'])):\n",
    "        mask1 = r1['masks'][:,:,i]\n",
    "        mask1 = np.where(mask1, 255, 0).astype(\"uint8\")\n",
    "        mask1 = cv.bitwise_and(image1,image1, mask=mask1)\n",
    "        if matching_order is None:\n",
    "            mask2 = r2['masks'][:,:,i]\n",
    "            mask2 = np.where(mask2 ,255, 0).astype(\"uint8\")\n",
    "            mask2 = cv.bitwise_and(image2,image2, mask=mask2)\n",
    "            show_images([[mask1],[mask2]],size=2)\n",
    "            continue\n",
    "        else:\n",
    "            mask2 = r2['masks'][:,:,matching_order[i]]\n",
    "            mask2 = np.where(mask2 ,255, 0).astype(\"uint8\")\n",
    "            mask2 = cv.bitwise_and(image2,image2, mask=mask2)\n",
    "        H = find_homography(mask1,mask2)\n",
    "        if H is not None:\n",
    "            h_arr.append(H)\n",
    "        else:\n",
    "            h_arr.append(np.zeros((3,3)))\n",
    "    assert matching_order is not None\n",
    "\n",
    "    \n",
    "    POINTS_PATH = os.path.join(PIXEL_DIR,f\"L{LEVEL1}\")\n",
    "    file_count = 0\n",
    "    for i in os.listdir(POINTS_PATH):\n",
    "\n",
    "        color = colors[file_count]\n",
    "        file_count = file_count + 1\n",
    "\n",
    "        cv.putText(c_image1, i.split('.')[0], (c_image1.shape[1]-1000, file_count*100),cv.FONT_HERSHEY_DUPLEX, 2, color, 2, cv.LINE_AA)\n",
    "        \n",
    "        mask1 = find_mask(i,LEVEL1,image1.shape[:2])\n",
    "        mask1 = cv.bitwise_and(image1,image1, mask=mask1)\n",
    "        mask2 = find_mask(i,LEVEL2,image2.shape[:2])\n",
    "        mask2 = cv.bitwise_and(image2,image2, mask=mask2)\n",
    "        \n",
    "        H = find_homography(mask1, mask2,verbose=True) \n",
    "        if H is not None:\n",
    "            print(i.split('.')[0])\n",
    "            index = find_best_match(H,h_arr)\n",
    "            mask = r1['masks'][:,:,index]\n",
    "            c_image1[mask] = color\n",
    "    \n",
    "    show_images([[c_image1]])\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homography_estimation_mask('three_top_indoor_i',63,67,matching_order=[0,1,2,3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Matching Function - VisBLE***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"BOY.... LETS DO IT....!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Matching Function- Initiative***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_the_points(case):\n",
    "    \n",
    "    # loading the mask_RCNN output\n",
    "    with open(os.path.join(MODEL_DIR,file_name+'.pkl'), 'rb') as f:\n",
    "        results = pickle.load(f)\n",
    "    r = results[0]\n",
    "    \n",
    "    threshold = .9\n",
    "    # Extracting bottles\n",
    "    bottle_index = np.array([i for (i, item) in enumerate(r['class_ids']) if class_names[item]=='bottle' and r['scores'][i]>threshold ])\n",
    "    masks = r[masks][bottle_index]\n",
    "\n",
    "    obj_count = 0\n",
    "    colors = [[255,0,0],[0,255,0],[0,0,255],[255,255,0]]\n",
    "\n",
    "    for i in os.listdir(PIXEL_DIR):\n",
    "        obj_count = obj_count + 1\n",
    "        pts = np.loadtxt(os.path.join(PIXEL_DIR,i), delimiter=',',usecols=(0,1)).astype(int)\n",
    "        cts = np.loadtxt(os.path.join(PIXEL_DIR,i), delimiter=',',usecols=(2)).astype(int)\n",
    "        if pts.ndim == 1:\n",
    "            pts = np.array([pts])\n",
    "        elif pts.ndim != 2:\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mask_RCNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "306617c3ad1fabe457fb34dc80ce7dc109d23c50097db84fd5264643d7853967"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
